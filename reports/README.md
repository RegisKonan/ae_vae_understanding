
# Title: Understanding Autoencoders and Variational Autoencoders

This [work](https://github.com/RegisKonan/ae_vae_understanding/blob/a00e1b481b5d796bc9fea429763acd4923cc4698/reports/Regis_Djaha_AMMI_project_2023.pdf) provides a comprehensive exploration of autoencoders (AEs) and variational autoencoders (VAEs), including beta-VAEs, which are fundamental unsupervised learning methods in artificial intelligence and machine learning. By delving into their theoretical underpinnings, practical implementations, and experimental analyses on benchmark datasets including MNIST, Fashion-MNIST, and FreyFace, the study enhances understanding of these modelsâ€™ capabilities in
data representation, dimensionality reduction, image generation, and latent space exploration. Insights into network architectures, the influence of hyperparameters, and the significance of priors contribute to advancing the effective utilization of AEs and VAEs across diverse application domains.
